<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2022-01-28 Fri 14:35 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Image Processing with ROS</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Matthew Elwin">
<link rel="stylesheet" href="./pubme.css" type="text/css"/>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="../index.html"> UP </a>
 |
 <a accesskey="H" href="./index.html"> HOME </a>
</div><div id="content">
<header>
<h1 class="title">Image Processing with ROS</h1>
</header><nav id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org4c02768">Overview</a></li>
<li><a href="#org34841c5">Cameras On Linux:</a></li>
<li><a href="#orgb121d6f">ROS Camera "Drivers"</a>
<ul>
<li><a href="#orga699c22">Using usb_cam</a></li>
<li><a href="#orgf0d9b02">Using cv_camera</a></li>
<li><a href="#org84bb1bd">Using libuvc_camera</a></li>
</ul>
</li>
<li><a href="#org6b8bf55">The Image Pipeline</a></li>
<li><a href="#org113c9a9">Other Image Tools</a></li>
<li><a href="#org35f101f">OpenCV</a></li>
<li><a href="#org4100121">Tag Tracking</a></li>
<li><a href="#org3dfd835">Other Image Packages and Libraries</a></li>
<li><a href="#org64ab873">Example Image Processing</a></li>
<li><a href="#orgd11a69b">Other Learning Resources</a></li>
</ul>
</div>
</nav>

<div id="outline-container-org4c02768" class="outline-2">
<h2 id="org4c02768">Overview</h2>
<div class="outline-text-2" id="text-org4c02768">
<p>
This lecture is about how to interface ROS with cameras and vision processing libraries.
</p>
</div>
</div>

<div id="outline-container-org34841c5" class="outline-2">
<h2 id="org34841c5">Cameras On Linux:</h2>
<div class="outline-text-2" id="text-org34841c5">
<ul class="org-ul">
<li>Cameras on Linux are viewed as files (like any other device).</li>
<li>Cameras on Linux are usually called <code>/dev/videoX</code>, where <code>X</code> is a number</li>
<li>Currently some cameras create two video devices, the lower numbered one is the one to use</li>
<li><code>v4l2-ctl</code> is a command line tool for interfacing with cameras. See <code>man v4l2-ctl</code></li>
<li><code>v4l2-ctl --list-formats-ext</code> prints useful information about the formats supported by cameras connected to your computer
<ul class="org-ul">
<li>You often need to specify these parameters to the ROS camera node, as parameters</li>
</ul></li>
<li><code>v4l2-ctl --all</code> prints all information about your cameras</li>
<li><code>v4l2-ctl --list-devices</code> Lists all the usb cameras.  Some cameras have
multiple <code>/dev/video*</code> devices so it is useful to see what goes with what</li>
<li>When working with cameras you should use <a href="http://www.reactivated.net/writing_udev_rules.html">udev rules</a> to give your cameras
the proper permissions and a persistent name.</li>
<li>More information can be found here:  <a href="https://www.kernel.org/doc/html/latest/driver-api/media/v4l2-core.html">V4l2</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgb121d6f" class="outline-2">
<h2 id="orgb121d6f">ROS Camera "Drivers"</h2>
<div class="outline-text-2" id="text-orgb121d6f">
<ol class="org-ol">
<li><a href="https://wiki.ros.org/usb_cam">usb_cam</a>  The main and most up-to-date ROS camera driver. Try this one first and prefer it to the others.</li>
<li><a href="http://wiki.ros.org/cv_camera">cv_camera</a> A camera driver that uses OpenCV to open the camera. So if you can use your camera in open CV this node should work</li>
<li><a href="https://wiki.ros.org/libuvc_camera">libuvc_camera</a> (not released for noetic)</li>
</ol>
<p>
Depending on your camera, one may work better than the other: libuvc is for cameras
that follow the UVC standard (most modern webcameras) and usb_cam uses the v4l framework (video for linux).
</p>

<ul class="org-ul">
<li>These camera nodes access your camera via the video device file (<code>/dev/videoX</code>)</li>
<li>These camera "drivers" accept several private parameters for setting camera options and formats.
<ul class="org-ul">
<li>Essentially, the node reads from the camera and publishes an image message</li>
</ul></li>
<li>Sometimes, you need to experiment with various options to get a usable webcam image.
<ul class="org-ul">
<li>If the node prints lots of warnings, it usually means a parameter like the image format should be changed</li>
<li>Other information that the node prints can be useful for debugging issues or tweaking parameters:</li>
<li>If possible, try to fix any warnings that you may find</li>
</ul></li>
<li>The image display type in rviz can be used to see the video from a camera</li>
<li>Other industrial cameras may have their own ROS node drivers, or you may need to write your own.</li>
<li><code>usb_cam</code> lets you access the camera via <code>/dev/videoX</code>, whereas <code>libuvc_camera</code> lets you access it
via Vendor Id (VID), Product Id (PID), and Serial number</li>
</ul>
</div>


<div id="outline-container-orga699c22" class="outline-3">
<h3 id="orga699c22">Using usb_cam</h3>
<div class="outline-text-3" id="text-orga699c22">
<ol class="org-ol">
<li>The camera is one of the <code>/dev/videoX</code> devices</li>
<li>Run the <code>usb_cam</code> node.  The basic parameters for most webcams are:
<code>rosrun usb_cam usb_cam_node _pixel_format:=yuyv</code></li>
<li><code>rosrun image_view image_view image:=/usb_cam/raw_image</code> to view</li>
<li>You can also view the image in <code>rviz</code> or <code>rqt_image_view</code></li>
</ol>
</div>
</div>

<div id="outline-container-orgf0d9b02" class="outline-3">
<h3 id="orgf0d9b02">Using cv_camera</h3>
<div class="outline-text-3" id="text-orgf0d9b02">
<ol class="org-ol">
<li>The camera is one of the <code>/dev/videoX</code> devices</li>
<li>Run the <code>cv_camera_node</code>. The basic parameters for most webcams are:
<code>rosrun cv_camera cv_camera_node</code></li>
</ol>
</div>
</div>
<details id="org84bb1bd"><summary class="header-3">Using libuvc_camera</summary>
<div class="outline-text-3" id="text-org84bb1bd">
<ol class="org-ol">
<li>Find the VID, PID, and Serial number of your camera: requires some investiagion
<ul class="org-ul">
<li><code>lsusb</code> - Print VID and PID of cameras on your computer</li>
<li><code>v4lctl --all</code> - See camera's attached to computer (can use this to guess which USB device it is)</li>
</ul></li>
<li>Create udev rules for the camera:
<ul class="org-ul">
<li>Copy udev rules to <code>/etc/udev/rules.d</code></li>
<li><code>sudo udevadm control --reload</code> (reloads udev rules)</li>
<li><code>sudo udevadm trigger</code> (re-runs udev rules)</li>
</ul></li>
<li>Start with the <a href="https://wiki.ros.org/libuvc_camera">launchfile</a> provided on the wiki and edit it to match your camera settings</li>
</ol>
</div>
</details>
</div>


<div id="outline-container-org6b8bf55" class="outline-2">
<h2 id="org6b8bf55">The Image Pipeline</h2>
<div class="outline-text-2" id="text-org6b8bf55">
<p>
<a href="http://wiki.ros.org/image_pipeline">image_pipeline</a> contains several packages relating to image manipulation in ROS.
The idea is to chain various calibration and image processing steps together to complete computer vision tasks.
The pipeline also applies to stereo-vision cameras and 3D point clouds as well as monocular images.
</p>
<ul class="org-ul">
<li>Note: if you get errors about the python interpreter not being found or missing <code>cv2</code>,
then you should install the perception pipeline from source in <code>~/customws</code>: <a href="https://github.com/ros-perception/image_pipeline">https://github.com/ros-perception/image_pipeline</a></li>
</ul>


<p>
<a href="http://wiki.ros.org/camera_calibation">Camera Calibration</a>
</p>
<ul class="org-ul">
<li>Finds the intrinsic parameters of a camera using a checkerboard pattern and OpenCV.</li>
<li>The calibration can be stored and used to provide a <code>camera_info</code> topic so that the calibration
can be used by other nodes. 
<ul class="org-ul">
<li>The <a href="http://docs.ros.org/api/sensor_msgs/html/msg/CameraInfo.html">CameraInfo Message Definition</a> has
some useful information</li>
</ul></li>
<li>See this <a href="http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration">tutorial</a></li>
<li>More information about camera calibration <a href="http://wiki.ros.org/image_pipeline/CameraInfo">CameraInfo</a></li>
<li>Some more information on calibration matrices for the <a href="http://ksimek.github.io/2012/08/13/introduction/#toc">pinhole camera model</a></li>
<li><a href="https://www.mathworks.com/help/vision/ug/camera-calibration.html">Matlab tutorial on camera calibration</a></li>
</ul>

<p>
<a href="http://wiki.ros.org/image_proc">image_proc</a>
   Camera lenses cause distortion.  Rectification is a transformation to make the image "rectangular" by accounting
   for camera lens distortion.  This node handles rectification for you:
  Subscribes to a raw camera image (<code>image_raw</code>) and camera calibration information <code>camera_info</code> and 
  publishes
</p>
<ol class="org-ol">
<li><code>image_mono</code>: A monochrome unrectified image</li>
<li><code>image_rect</code>: A monochrome rectified image</li>
<li><code>image_color</code>: A color unrectified image. These images are de-omsaiced 
(that is it accounts for the rgb pixel pattern of the camera)</li>
<li><code>image_rect_color</code> A color rectified image.</li>
</ol>

<p>
<a href="http://wiki.ros.org/image_view">image_view</a>
</p>
<ul class="org-ul">
<li>Simple, stand-alone image viewer.  Specify the <code>raw_image</code> topic as a parameter and it will display the image</li>
<li>There is also <code>rqt_image_view</code> (although that is part of rqt, not the image pipeline)</li>
</ul>
<p>
<a href="http://wiki.ros.org/depth_image_proc">depth_image_proc</a> Processes depth image
</p>
<ul class="org-ul">
<li>In a depth image, each pixel corresponds to the depth (i.e., how far light has to travel before hitting something)
in the scene.</li>
<li>Used by RGB-D cameras such as the intel RealSense.</li>
<li>Used to make point clouds (basically 3 dimensional pixelized images) from calibrated depth cameras</li>
</ul>
</div>
</div>

<div id="outline-container-org113c9a9" class="outline-2">
<h2 id="org113c9a9">Other Image Tools</h2>
<div class="outline-text-2" id="text-org113c9a9">
<ol class="org-ol">
<li><a href="http://wiki.ros.org/image_transport">Image Transport</a> determines how image data is sent across the system.</li>
</ol>
<p>
Rather than raw camera data, the image data can be compressed to use less bandwidth.
For python usage, the <code>republish</code> feature is the most important
</p>

<ol class="org-ol">
<li><a href="http://wiki.ros.org/web_video_server">Web Video Server</a> used to create an http stream of video,
useful if interfacing your robot to a website.</li>
</ol>
</div>
</div>

<div id="outline-container-org35f101f" class="outline-2">
<h2 id="org35f101f">OpenCV</h2>
<div class="outline-text-2" id="text-org35f101f">
<p>
<a href="https://opencv.org">OpenCV</a> is a major image processing library.
Their website has many tutorials on how to process images.
</p>

<p>
Some packages that use/relate to OpenCV are:
</p>
<ol class="org-ol">
<li><a href="http://wiki.ros.org/cv_bridge">cv_bridge</a> Converts between OpenCV data and ROS messages.
<ul class="org-ul">
<li>If you want to use opencv with ROS, you should use this package</li>
</ul></li>
<li><a href="http://wiki.ros.org/opencv_apps">opencv_apps</a> Each "app" is a node that performs a single
image processing function using opencv.  Thus you can chain together many computer vision algorithms
by connecting some nodes together in a launchfile.</li>
<li><a href="https://wiki.ros.org/image_geometry">image_geometry</a> Using a camera calibration,
lets you convert between pixel coordinates and the other frames in your system.
<ul class="org-ul">
<li><a href="http://docs.ros.org/en/melodic/api/image_geometry/html/python/">Python API documentation</a></li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org4100121" class="outline-2">
<h2 id="org4100121">Tag Tracking</h2>
<div class="outline-text-2" id="text-org4100121">
<p>
Tags are special 2-Dimensional patterns that are designed to be viewed with a camera. 
Computer vision algorithms can then determine the 6 Degree of freedom pose of the tag and
often an identifier (thus Tags are like QR codes but they also contain geometric information.
</p>

<p>
The best tags to use are April tags.  
</p>
<ul class="org-ul">
<li><a href="http://wiki.ros.org/apriltag_ros">apriltag_ros</a></li>
<li><a href="https://april.eecs.umich.edu/software/apriltag">Information on the Theory of April Tags</a></li>
</ul>

<p>
Prior to the invention of April tags, AR tags were a popular choice for tag tracking.
These were popular enough at a time that many people (included me) still say "AR tag".
</p>
<ul class="org-ul">
<li>If I say this, please correct me, I mean April tags.</li>
</ul>

<p>
I see no reason to use this package over apriltag_ros, but you may encounter other packages that use it.
</p>
<ul class="org-ul">
<li><a href="http://wiki.ros.org/ar_track_alvar">ar_track_alvar</a></li>
</ul>

<p>
There are many other types of tags, that have different properties: for example  <a href="http://wiki.ros.org/aruco_detect">aruco tags</a>.
</p>
</div>
</div>


<div id="outline-container-org3dfd835" class="outline-2">
<h2 id="org3dfd835">Other Image Packages and Libraries</h2>
<div class="outline-text-2" id="text-org3dfd835">
<ol class="org-ol">
<li><a href="http://wiki.ros.org/darknet_ros">Darknet ROS</a> - realtime object detection</li>
<li><a href="https://github.com/tzutalin/awesome-visual-slam">Up to date list of visual SLAM solutions</a></li>
<li><a href="http://wiki.ros.org/face_detector">face_detector</a></li>
<li><a href="http://wiki.ros.org/face_recognition">facial_recognition</a> You will need to compile this since it was last
released for ROS indigo.</li>
<li><a href="http://florisvb.github.io/multi_tracker/">2D tracking of multiple objects</a></li>
<li><a href="http://wiki.ros.org/find_object_2d">Find object 2D</a> Feature detection to find objects</li>
</ol>
</div>
</div>



<div id="outline-container-org64ab873" class="outline-2">
<h2 id="org64ab873">Example Image Processing</h2>
<div class="outline-text-2" id="text-org64ab873">
<ul class="org-ul">
<li>See <a href="https://github.com/m-elwin/me495_image.git">https://github.com/m-elwin/me495_image.git</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgd11a69b" class="outline-2">
<h2 id="orgd11a69b">Other Learning Resources</h2>
<div class="outline-text-2" id="text-orgd11a69b">
<ul class="org-ul">
<li><a href="https://ciechanow.ski/cameras-and-lenses/">Cameras and Lenses</a> (Highly recommend this)</li>
<li><a href="http://mrcal.secretsauce.net/">mrcal</a> NASA-quality lenses modeling and calibration software.</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p><p class="outline-2">Author: Matthew Elwin</p></p>
</div>
</body>
</html>
